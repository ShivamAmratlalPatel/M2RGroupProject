\documentclass{beamer}
\usepackage[utf8]{inputenc}

\usetheme{Madrid}
\usecolortheme{default}

%------------------------------------------------------------
%This block of code defines the information to appear in the
%Title page
\title{}

\subtitle{}

\author{}

\institute{}

\date{}


%End of title page configuration block
%------------------------------------------------------------


%------------------------------------------------------------
%The next block of commands puts the table of contents at the 
%beginning of each section and highlights the current section:

\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table of Contents}
        \tableofcontents[currentsection]
    \end{frame}
}
%------------------------------------------------------------


\begin{document}

%---------------------------------------------------------
%Changing visivility of the text
    \begin{frame}
        \frametitle{Upper-Confidence-Bound(UCB)}
        Choose the arm with the highest UCB to pull next

        \begin{itemize}
            \item<1-> True value $ Q(a)  \leq \widehat{Q_t (a)}+\widehat{U_t (a)} $
            \item<2->  $ \widehat{Q_t (a)}$ is the sample mean and $ Q(a)$ is the true mean
        \end{itemize}
    \end{frame}

%---------------------------------------------------------


    \begin{frame}
        \frametitle{Hoeffdingâ€™s Inequality}
        Let $X_1, \dots, X_n$ be independent and identically distributed random variables

        \begin{itemize}
            \item<1-> $ P(E[X] > \overline  X_t + u) \leq e^{-2t u^2}$
            \item<2-> $P[Q(a) >\widehat{Q_t (a)}+\widehat{U_t (a)}] \leq e^{-2t U_t(a)^2}$
            \item<3-> $U_t(a) = \sqrt{\frac{-\log p}{2N_t (a)}}$
        \end{itemize}
    \end{frame}


%------------------------------------------------------------

    \begin{frame}
        \frametitle{UCB1}
        Achieving logarithmic regret uniformly over $n$ and without any preliminary knowledge about the reward distributions.

        \begin{itemize}
            \item<1-> $\overline X_t + \sqrt{\frac{2log t}{N_t (a)}}$
            \item<2-> logarithmic regret $O(\log N)$ on [0,1]

        \end{itemize}
    \end{frame}


%------------------------------------------------------------
    \begin{frame}
        \frametitle{KL-UCB}
        We first pull each arm once and choose the next pull according to regret bounds rely on deviations results of independent interest.

        \begin{itemize}
            \item<1->$\lim_{n\to \infty} \frac{E[R_n]}{\log n} \leq  \sum_{a:u_a < u_{a*}} \frac{u_{a*}-u_a}{d(u_a,u_{a*})}  $
            \item<2->  $d(p, q) = p \log(p/q) + (1 - p) * \log((1 - p/(1 - q))$
            \item<3->  K is the number of arms, a* is the optimal arm and independent rewards bounded in [0,1]
        \end{itemize}
    \end{frame}

%---------------------------------------------------------
    \begin{frame}
        \frametitle{Strengths of UCB}

        \begin{itemize}
            \item<1-> quicker than the greedy algorithm
            \item<2->  UCB-1 results are very stable and similar to the average results.
            \item<3->   KL-UCB algorithm satisfies a uniformly better regret bound than UCB and its variants. Any maximizer can be chosen in this strategy
        \end{itemize}
    \end{frame}

%---------------------------------------------------------
    \begin{frame}
        \frametitle{Weakness of UCB}

        \begin{itemize}
            \item<1->  performance deteriorates much more quickly than that of other algorithms when K becomes large
            \item<2->  choice of confidence interval also affects the precision
            \item<3->  UCB1 converges to a solution much more slowly than the other algorithms
        \end{itemize}
    \end{frame}


%---------------------------------------------------------
    \begin{frame}
        \frametitle{GLR-klUCB}
        This algorithm combines the efficient bandit algorithm klUCB, with a parameter- free, change-point detector, the Bernoulli Generalized Likelihood Ratio Test.
        \begin{itemize}
            \item<1->  $ O\left(\Upsilon_T \sqrt{T \log\left(T\right)} \right)$ if the number of changed points $\Upsilon_T $ is unknown
            \item<2->   and $ O\left(\sqrt{\Upsilon_T T \log\left(T\right)} \right)$ if  $\Upsilon_T $ is known

        \end{itemize}
    \end{frame}


\end{document}